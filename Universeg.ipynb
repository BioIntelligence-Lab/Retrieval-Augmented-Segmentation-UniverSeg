{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from utils import visualize_tensors,inference,plot_tensor,inference_mix_prec\n",
    "from support_image_import import *\n",
    "from collections import defaultdict\n",
    "from prune_model import prune_model\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(156)\n",
    "np.random.seed(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn \n",
    "sys.path.append('UniverSeg')\n",
    "\n",
    "\n",
    "from universeg import universeg\n",
    "model = universeg(pretrained=True)\n",
    "model = model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (256,256)\n",
    "support_size = 64\n",
    "#modify the images folder\n",
    "support_images_folder = \"data/all2/images\"\n",
    "support_masks_folder = \"data/all2/mask\"\n",
    "image_path = \"data/test/images/ISIC_0000137.jpg\"\n",
    "test_images = \"data/test/images\"\n",
    "test_masks = \"data/test/mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#structural_comparison original algorith with gpu\n",
    "sp_im,sp_ms,img_test = import_support_image_structural(support_size,support_images_folder,support_masks_folder,image_path,device,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_vector_comparison\n",
    "sp_im,sp_ms,img_test = import_support_image_dense_vector(support_size,support_images_folder,support_masks_folder,image_path,device,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hash comparison\n",
    "sp_im,sp_ms,img_test = import_support_image_hash(support_size,support_images_folder,support_masks_folder,image_path,device,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hash with augmentation\n",
    "sp_im,sp_ms,img_test = import_support_image_hash_aug(support_size,support_images_folder,support_masks_folder,image_path,device,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lpips comparison\n",
    "sp_im,sp_ms,img_test = import_support_image_lpips(support_size,support_images_folder,support_masks_folder,image_path,device,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img,test_mask,_ = import_support_image_lpips(8,test_images,test_masks,image_path,device,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the support images\n",
    "plot_tensor(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune model test\n",
    "prune_model(model,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model increase the support image size but loss some speed\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_support = 36\n",
    "# run inference\n",
    "arrtest1 = sp_im[:num_support].detach()\n",
    "arrtest2 = sp_ms[:num_support].detach()\n",
    "with torch.inference_mode():\n",
    "    logits = model(img_test[None].to(device), arrtest1[None].to(device), arrtest2[None].to(device))[0].to('cpu').float()\n",
    "pred = torch.sigmoid(logits)\n",
    "# visualize\n",
    "res = {'data': [img_test, pred, pred > 0.5]}\n",
    "titles = col_names=['image', 'pred (soft)', 'pred (hard)']\n",
    "visualize_tensors(res, col_wrap=3, col_names=titles)\n",
    "del logits,pred,res\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run multiple predictions\n",
    "n_predictions = 6\n",
    "num_support = 32\n",
    "idxs = np.random.permutation(len(test_img)-1)[:n_predictions]\n",
    "time = []\n",
    "# run inference\n",
    "arrtest1 = sp_im[:num_support]\n",
    "arrtest2 = sp_ms[:num_support]\n",
    "results = defaultdict(list)\n",
    "x = datetime.datetime.now()\n",
    "for i in tqdm(idxs):\n",
    "    x = datetime.datetime.now()\n",
    "    image, label = test_img[i],test_mask[i]\n",
    "    vals = inference(model, image, label, arrtest1, arrtest2,device)\n",
    "    for k, v in vals.items():\n",
    "        results[k].append(v)\n",
    "    del image,label,vals\n",
    "    torch.cuda.empty_cache()\n",
    "    y = datetime.datetime.now()\n",
    "    time.append(y-x)\n",
    "scores = results.pop('score')\n",
    "visualize_tensors(results, col_names=[f'Dice = {100*s:.1f}' for s in scores], title='Test Predictions - Different Label', col_wrap=n_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return time and inference score mean\n",
    "scores1 = np.array(scores)\n",
    "scores1 = np.nan_to_num(scores).mean() \n",
    "print(\"mean dice score:\",scores1)\n",
    "sum = datetime.datetime.now() - datetime.datetime.now()\n",
    "for i in range(n_predictions):\n",
    "    sum += time[i]\n",
    "print(\"mean time per inference:\",sum / n_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run multiple predictions on mixed presition\n",
    "\n",
    "n_predictions = 6\n",
    "num_support = 32\n",
    "idxs = np.random.permutation(len(test_img)-1)[:n_predictions]\n",
    "time = []\n",
    "# run inference\n",
    "arrtest1 = sp_im[:num_support]\n",
    "arrtest2 = sp_ms[:num_support]\n",
    "results = defaultdict(list)\n",
    "x = datetime.datetime.now()\n",
    "for i in tqdm(idxs):\n",
    "    x = datetime.datetime.now()\n",
    "    image, label = test_img[i],test_mask[i]\n",
    "    vals = inference_mix_prec(model, image, label, arrtest1, arrtest2,device)\n",
    "    for k, v in vals.items():\n",
    "        results[k].append(v)\n",
    "    del image,label,vals\n",
    "    torch.cuda.empty_cache()\n",
    "    y = datetime.datetime.now()\n",
    "    time.append(y-x)\n",
    "scores = results.pop('score')\n",
    "visualize_tensors(results, col_names=[f'Dice = {100*s:.1f}' for s in scores], title='Test Predictions - Different Label', col_wrap=n_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return time and inference score mean\n",
    "scores1 = np.array(scores)\n",
    "scores1 = np.nan_to_num(scores).mean() \n",
    "print(\"mean dice score:\",scores1)\n",
    "sum = datetime.datetime.now() - datetime.datetime.now()\n",
    "for i in range(n_predictions):\n",
    "    sum += time[i]\n",
    "print(\"mean time per inference:\",sum / n_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on different support size\n",
    "import pandas as pd\n",
    "n_predictions = 2\n",
    "support_set_sizes = [1, 2, 4, 8,16,32,64]\n",
    "\n",
    "scores = []\n",
    "scores1 = []\n",
    "for i in idxs:\n",
    "    results = defaultdict(list)\n",
    "    for N in tqdm(support_set_sizes):\n",
    "        image, label = test_img[i],test_mask[i]\n",
    "        vals = inference(model, image, label, sp_im[:N], sp_ms[:N],device)\n",
    "        for k, v in vals.items():\n",
    "            results[k].append(v)\n",
    "        del image,label,vals\n",
    "        torch.cuda.empty_cache()\n",
    "    scores.append(results['score'])\n",
    "\n",
    "    #uncomment the next lines to plot the predictions\n",
    "\n",
    "    #scores = results.pop('score')\n",
    "    #col_names = [f'N = {N}' for N in support_set_sizes]\n",
    "    #col_names = [col+f'\\nDice: {100*score:.1f}' for col, score in zip(col_names, scores)]\n",
    "    #visualize_tensors(results, col_names=col_names, title='Test Predictions for varying Support Set size $N$', col_wrap=len(support_set_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot basic stats to compare the results of different support sizes\n",
    "df = pd.DataFrame(scores)\n",
    "df.columns = support_set_sizes\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "scores = results.pop('score')\n",
    "col_names = [f'N = {N}' for N in support_set_sizes]\n",
    "col_names = [col+f'\\nDice: {100*score:.1f}' for col, score in zip(col_names, scores)]\n",
    "visualize_tensors(results, col_names=col_names, title='Test Predictions for varying Support Set size $N$', col_wrap=len(support_set_sizes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
